{
    "selectedEnvs": {},
    "bestCurriculas": {},
    "curriculaEnvDetails": {
        "epoch_1": [
            "MiniGrid-Dynamic-Obstacles-16x16-custom-diff1.0",
            "MiniGrid-Dynamic-Obstacles-16x16-custom-diff1.0",
            "MiniGrid-Dynamic-Obstacles-16x16-custom-diff1.0",
            "MiniGrid-Dynamic-Obstacles-16x16-custom-diff1.0"
        ],
        "epoch_2": [
            "MiniGrid-Dynamic-Obstacles-16x16-custom-diff1.0",
            "MiniGrid-Dynamic-Obstacles-16x16-custom-diff1.0",
            "MiniGrid-Dynamic-Obstacles-16x16-custom-diff1.0",
            "MiniGrid-Dynamic-Obstacles-16x16-custom-diff1.0"
        ],
        "epoch_3": [
            "MiniGrid-Dynamic-Obstacles-16x16-custom-diff1.0",
            "MiniGrid-Dynamic-Obstacles-16x16-custom-diff1.0",
            "MiniGrid-Dynamic-Obstacles-16x16-custom-diff1.0",
            "MiniGrid-Dynamic-Obstacles-16x16-custom-diff1.0"
        ]
    },
    "rawRewards": {
        "epoch_1": [
            0.0,
            0.0,
            0.0,
            0.0
        ],
        "epoch_2": [
            0.0,
            0.0,
            0.0,
            0.0
        ],
        "epoch_3": [
            0.0,
            0.0,
            0.0,
            0.0
        ]
    },
    "curriculumRewards": {},
    "actualPerformance": {},
    "maxStepReward": 35,
    "maxCurricReward": null,
    "epochsDone": 4,
    "done": false,
    "epochTrainingTime": [
        27.441997,
        27.698807,
        27.621135
    ],
    "snapshotScore": [
        0.0,
        0.0,
        0.0
    ],
    "sumTrainingTime": 82.761939,
    "cmdLineString": "/home/schlecht/nobackup/MinigridCurriculumLearning/scripts/trainCurriculum.py --trainAllParalell --model debPPO_16x16_lr --iterPerEnv 50000 --procs 16 --ppoEnv 3 --dynamicObstacle --seed 12 --episodes 8 --lr .1",
    "difficultyKey": [
        1.0,
        1.0,
        1.0,
        1.0
    ],
    "seed": 12,
    "iterationsPerEnv": 50000,
    "consecutivelyChosen": 0,
    "args": "Namespace(dynamicObstacle=True, constMaxsteps=False, trainAllParalell=True, asCurriculum=False, ppoEnv=3, allSimultaneous=True, trainRandomRH=False, iterPerEnv=50000, paraEnv=2, stepsPerCurric=3, numCurric=3, difficultyStepsize=100000, trainingIterations=5000000, nGen=3, gamma=0.9, noRewardShaping=False, useNSGA=False, multiObj=False, crossoverProb=0.8, mutationProb=0.8, crossoverEta=3.0, mutationEta=3.0, model='debPPO_16x16_lr', seed=12, procs=16, epochs=4, batch_size=256, frames_per_proc=None, discount=0.99, lr=0.1, gae_lambda=0.95, entropy_coef=0.01, value_loss_coef=0.5, max_grad_norm=0.5, optim_eps=1e-08, optim_alpha=0.99, clip_eps=0.2, recurrence=1, text=False, episodes=8, argmax=False, worst_episodes_to_show=10, memory=False, log_interval=1, save_interval=2, mem=False, trainEvolutionary=False)",
    "usedEnvEnumeration": [
        "MiniGrid-Dynamic-Obstacles-5x5",
        "MiniGrid-Dynamic-Obstacles-6x6",
        "MiniGrid-Dynamic-Obstacles-8x8",
        "MiniGrid-Dynamic-Obstacles-16x16"
    ],
    "additionalNotes": "",
    "numFrames": 153600,
    "currentListOfCurricula": [
        "MiniGrid-Dynamic-Obstacles-16x16-custom-diff1.0",
        "MiniGrid-Dynamic-Obstacles-16x16-custom-diff1.0",
        "MiniGrid-Dynamic-Obstacles-16x16-custom-diff1.0",
        "MiniGrid-Dynamic-Obstacles-16x16-custom-diff1.0"
    ]
}