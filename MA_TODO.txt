Random Gedanken
- Wie damit umgehen, dass man evtl nicht alles 1:1 gleich lang machen muss? zB Man kann 200k trainieren 16x16, und 100k 8x8 reicht zum stabilisieren
- Darf ich händisch etwas zum abbrechen einbauen oder sind die extra iterationen dann noch sinnvoll? zB value > .8
- RH Probleme? Was wenn man zB erst 2 Mio mal 16x16 trainieren muss, bevor man Fortschritte sieht? Wenn 1 Horizon bei 500k ist
- Gefahr der schnellen Konvergenz: gerade 5&6 sind zu easy. 8x8
- Gefahr für feste Iterationslänge? Wenn man 250k fest hat, aber zB manchmal 400k das eine, dann 500k das andere besser ist (oder ist das so unwahrscheinlich dass das einfluss auf die gelernten gewichte etc hätte?
- Nach 100k + Iterationen verlernt er bei 16x16 alles --> schlechtes ergebnis
------------------------------------------
Features/Main
Baseline: 20 Mio iterationen (zb 1,2,4, 15 mio) --> nachher 2h laufenlassen
Baseline2: 8x8 in 2 Mio lernen, dann toggle zwischen 16 und 8 für jeweils X iterationen
Random rH: 5 Mio curriculum insg?
# Curriculum where every time the order changes for the next iteration
# or maybe do linear with that order then ??

mail:
- EA ausbauen (Representation extending
- Auswertung eines Trainingsrun
- Vergleich mit Baseline (stück für stück steigern)


--- andere todos ---
- Baseline trainieren & abspeichern
- argparse verbessern
- train/evaluate in anderen Ordner, scripts nur für ausführbares
-



- Wenn man während des Trainings abbricht, sollten entweder alle _curric_ status gelöscht werden oder noch zusätzlich gespeichert werden, damit man exakt weiß, wo man war
- später:  curricula  evol erstellen (oder varianten)
- später: Visualisieren, wann was gelernt wurde und co


Paar Ideen / Maybes
- Ladezeiten optimieren
- Evaluation: use weights, maybe depending on progress ;  maybe use something else like Value / Policy Loss / Frames
- assert dass neuladen gleiche anzahl an curricula wie vorher ist

Small Refactorings
- use os . join for these things os.getcwd() + "\\storage\\" + directory)
- besseres args unpacking

---------------


TODO Nächste Woche:
- log
später:  curricula  evol erstellen (oder varianten), random curricula zum anfang
- rewards loggen
- Plot überlappen
- Auswählen ; Tracking

5 Mio insg;
alle 250k  ändern


Mi 14 Uhr


----

- Zustand backup nach jedem Curriculum, und das dann am Anfang laden

Hyperparameter: Epochs, HorizonLength, pretraining, ggf die Curricula??

- Load status to read exact number of frames ( and calculate how much can be done)
