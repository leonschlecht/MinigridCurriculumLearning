pymoo --> usually used for multiobjective;
define problem: minigrid with curriclum; return reward; eg use non dominatesd sorting algoirthm, NSGA-III
----------------------------------------------------------------------------

- Was für Env-Iterationen, Curriculum-Länge & -Anzahl werden überhaupt angestrebt?
- wie kann man denn "etwas besser lernen" feststellen in minigrid? Entweder kann der agent es oder nicht
- Kann man vllt so die Minigrid anpassen, dass ich nicht manuell auf register(...) in meinen inits zurückgreifen muss?
- Das Unlearning Problem: wie genau funktionieren die updates überhaupt (2560 update schritte, oder 1x pro level)


-------------------
- Wie damit umgehen, dass man evtl nicht alles 1:1 gleich lang machen muss? zB Man kann 200k trainieren 16x16, und 100k 8x8 reicht zum stabilisieren
- RH Probleme? Was wenn man zB erst 2 Mio mal 16x16 trainieren muss, bevor man Fortschritte sieht? Wenn 1 Horizon bei 500k ist & die Iterationen pro Env noch niedriger sind
------------------------------------------


- Wenn man während des Trainings abbricht, sollten entweder alle _curric_ status gelöscht werden oder noch zusätzlich gespeichert werden, damit man exakt weiß, wo man war


Paar Ideen / Maybes
- Ladezeiten optimieren
- Evaluation: use weights, maybe depending on progress ;  maybe use something else like Value / Policy Loss / Frames

Small Refactorings
- use os . join for these things os.getcwd() + "\\storage\\" + directory)

-------------------

