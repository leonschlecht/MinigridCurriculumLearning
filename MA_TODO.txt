eval "$(~/tmp/Anaconda/home/schlecht/AnacondaNeu/bin/conda shell.bash hook)"

Todo für @home /Sonntag
- SPLCL 10 runs starten;  (--> VORHER PULLEN)

- NSGA multiobj run auf cluster starten

- SAC ausprobieren mit besserer HW


- Gruppierungen für 2curric vs 3 vs 4 (vs 1 evtl auch noch) (auch für nGen und curricLength; damit ich den teil abschließen kann !)

- evtl noch einen anderen single obj starten
- CL Baseline (REIHENFOLGE statt alles gleichzeitig !!!)

SAC todo:
numFrames herausfinden
schauen wie ich das speichern kann
irgendwie in meins einbetten (basierend auf iterPerEnv starten)


@Alex:
Zeigen wie agent in 12x12 performt mit PPO ohne alles



-------------------------------


Results chapter structure:
- 5kk
    - RHEA CL (GA dann NSGA)
        - beide vseinander
        - einzelne params vergleichen (und ggf 1-3 plots noch dazu packen --> welcher param zu low = schlecht;
            welcher param höher wirkt vielversprechend?
1230 @rrh --> begriffe vereinhetilichen kurz satz erwähnen

Next week wichtig:
- SAC hinbekommen ODER anderen Algo (Oder es sein lassen)
- Env Distributions genug text geschrieben(-> verstehen und erklären was wann passierti m algo)
- bonus: aus welcher gen kam das selektierte curriculum
- Mergen von dem Results chapter fertig

- evtl die Legend bei den plots umbenennen (damit es einheitlich ist mit denn namen die ich bnenutze in meiner arbeit)


General todo:
- alle Plots noch mal überarbeiten (2h) (NSGA 5kk, GA 5kk, Gruppierung nach curricCount, nGen, curricLength;	crossoverMutation comparisons
- Discussion Chapter zusammenführen
+ auswertung für die Crossover / Mutation rates (inkl Distributions --> Auswirkungen des eAs besser verstehen)
+ ggf puren NSGA vs GA plot, wo nur experimente sind die in beiden varianten ausgeführt wurden
1 - (bei ssh aufräumen)
1 - evtl mit mehr als 1-2 CPUs ausprobieren
- RQ2 überarbeiten, weil ich ja gar nicht auf konvergenz untersucht habe
- plot für aus welcher gen das gewählte curriculum kam
- evtl mal ein plot mit RRH CI/SD vs RHEA CL CI/SD, damit man die unterschiede besesr sehen kann
- Plot für den effekt, den man eigentlich erzielen möchte (Basics Teil, ggf Methodology)
- neue 25k 4s 3 3 run starten (Bzw testen warum es so unlucky war ?)
- climbing speed signifikanztest ???
- Elitismus und NSGA
- Pseudocode für Methodology
- "sag mir noch mal bescheid wenn du das platziert hast" (5 tmp)
- steigt GA oder NSGA schneller an in 1kk? -> Hypothesentest
- - 1kk vs 2kk vs 3 vs 4 vs 5kk distributions der environments anschauen

Prog: - Boxplots der gruppierungen zeigen (k steps, nGen, ...)
schreib:
1 - chapter referenzieren (in 1.3 und generell)
3 - vor und nachteile der einzelenn ansätze erläutern (basics)
3 - domain kapitel aufteilen in kleinere bzw einfach am rand erwähnen
3 - mehr zu CL und lokale minimum
3 - EA Quellen
3 - EA: roulette wheel ; fitness proportional usw verbessern
- \textit beim EA Kapitel: Wo genau hin überprüfen
- NSGA besser erklären, ggf mit einer Grafik & warum es eigentlich für multiobjetive gedacht ist) (auf corwding distance eingehen) & erwähnen, dass man es auch für single objectives benutzen kann
- RH Quelle
- RH: at first glance absatz verbessern --> diesen RH algorithmus vs iteration eines Algorithmus (ggf als begriff einführen)
- MCTS Quelle / RHEA Quelle
- vornachteile in basics kapitel einzelner ansätze
- domain basic teil rausnehmen (bzw in verkürzer form an anderen sachen einbringen)
- cl local minimum in more depth
- EA Quelle
- RW so anpassen, dass man je nach domain noch bestimmt gos/nogos erwähnt für die Algorithmen
- Sorgen: Begründung mit NSGA2. Warum überhaupt unterschiedlichen Effekt wenn single objective. Sehr reingeprägt als Multiobjective Problem
---> starker elitismus (auch in basic erläutern)
- multiobjective & singleobjective quelle da einbinde




Low prio todo
- vllt mal die todos im code bearbeiten



Iwo einfügen
- diesen dip versuchen auszubalancieren, der durch die maxSteps entstanden ist wurde mal probiert
- Could have also made a stop at like .5 for 1kk and then go down all the way to .1 or so. (An alternative you could have used was to make it more like a step function, which stays the same for a bit of time, and the ncontinues to go down (right now it stays the same for 500k, then goes down linearly until .15, and then stays the same again
- exp setup: Anfang refrenz für die komplett-tabelle am ende


Schreib-Ideen
- Constraints einfügen für bessere balance (zb Relationship zwischen den einzelnen env-rewards --> Multi obj wäre besser) ; oder threshold rewards (ggf punishen, falls darunter)



--------------------------------------------------------------------------------------------------------
Random:
- das ist super unclean geworden wegen der mutation/crossover probability und dass ich das jetzt hier und mal da geändert habe
- alle C runs beschränken auf durchschnitt oder min der frames done

Do:
d - RRH Traning time plot (wo die y achse auch passend ist und verlgiechbar mit den anderen)
d - time plots neu (alle zusammen, spezifisches NSGA vs GA)
d - time plot sortieren nach iterationSteps
d - Realtiver env distribution plot. Ggf auch env distr ohne SD anzeigen
d - SPLCL logs sind broken (aber ab wann`???)
d - ich glaub nen neues experiment machen, so dass ich sagen kann "zu hoch" ist schlecht fürCoMu
d - 1kk performacne: SPLCL fehlt
d - Experimente Tabelle machen (erstmal in google)
d + plot sortieren !! (250k muss rechts sein)
d - plot of snapshotScore vs actualScore


Fr
d eval --> args.procs mit args.episodes ersetzen (sofern es kleiner ist)
(halb)- das mit den distributions hinbekommen (1-2h)
(notizen)- Feedback einarbeiten (2-3h) (erstmal notizen machen)
d- anderes auch begradigen damit es einheitlich ist (zB manches RRH)
d? - SAC weitermachen
d - größere Achsenbeschriftungen
d - NSGA mehrdimensional (also 4 objectives



Sa
Schreibtag
step plot fix
paar kleinigkeiten

--------------------------------------
- internal / external validation ?
Stackedbarplot performance (NSGA vs GA vs RRH vs AP vs SPLCL)

Experimente:
- mit anderem ALgorithmus ( SAC / TD3 )
- mit anderen Gamma raten
- mit / ohne Rewardshaping vergleichen
- mit anderen curricLengths (--stepsPerCurric)

Experiment Ideen:
- episoden pro eval verringern ( ziel schneller evaluieren)
- andere envGrößen
- andere Viewsize
- Andere Minigrid Envs?
- Ganz andere Envs?




- ggf neue experimente queuen, die den stepSize etwas rumprobieren (oderz umidnst schuaen wasi chs chonp robiert hatte und warum ich das nicht weiterverfolgt hatte usw)
- evtl mehr expeirmente mit norewardshasping machen
-- alte models automatisch löschen (ic hglaube das könnte schon ziemlich viel zeit sparen, damit git schneller ist und vllta uf dem cluster weniger schiefläuft. Aber ich weiß nicht genau, ob das blöd ist, wenn im Cluster immer so viel hin und hergeschrieben wird)


Heute:
- Kapitel 4 V1 fertig
- überlegen, welche Grafiken in Kapitel 4 passen könnten
- mit dem SAC weiterprobieren

- Grafik mit SPLCL Runs (bzw allen)
- 6 8 10 12 switch baseline (welches CL ist das? Gibt es iwi eine Literatur, die das vorschlägt)

Morgen:
- überlegen, wie ich alle 1kk env distribution oder so hinbekomme ( AUFGABENSTELLUNG !!!)
- Kapitel 4 fertig;
- Kapitel 5 etwas verfeinert
- Überlegen, welche runs noch fehlen (und die dann starten)

Fr:
- Kapitel 5 fertig
- Kapitel 6 etwas verfeinert
- Runs alle rüberkopiert, crMu Run5050 nach -> 54 56

Sa: Kapitel 6 fertig

So:
Proofreading K4,5,6 & abschicken


Andere Todos:
- Experimente:
-   - Mehr Runs ohne Rewrad Shaping
    - mit anderem algorithmus
    - mit anderen Gamma raten (evtl kombinieren mit curric Längen)
     mit anderen curricLengths (--stepsPerCurric)
     - weniger episoden pro eval
     - andere EnvGrößen & viewsize
     - andere minigrid envs?
- SPLCL runs rüberkopieren
- Grafiken zu SPLCL runs erstellen
- Time investieren in Groupbarchart (brauch generell für eig alles ist das useful)
- Verbessern der benutzen grafiken für die MA (--> vorher überlegen, welche ich eigentlihc brauche bzw. welche ich generieren kann und was für aussagen ich treffen möchte)
- eval README(und ggf kleine doc schreiben dmait es consistent ist und ich nicht jedes mal in iwelche probelem laufe)
- Kapitel 4 schreiben
- Kapitel 5 schreiben
- Kapitel 6 schreiben


Todos:
- scatterplot evtl für training time (NSGA, ..)
- xtick 45 grad & ---> verschieben ha=right (- rotation=45, ha='right')
- filter nach Methode (zB 100k, oder alle 3Gen, ...) --> schauen was ich noch nicht alles implemetneirt habe und wonach ich noch filtern önnte
- Idee vom RHEA CL Plot machen (kannst ja eigene daten erstellen dafür)
    - auch ein mal actual progression visualisieren (wie sich etwas in 1 epoche entwickelt hat)
!! Baselines mal genauer aufschlüsseln und schaune was ich schon habe, bzw was ich noch leicht implementieren könnte
- filter nach Methode (zB 100k, oder alle 3Gen, ...)


- I could use difficult for the pool of available curricula as well (to better adjust to the models performacne); so it would have more to choose from, but then the evol optim would take a lot longer
-Plot: time of 2 curric vs 3 curric vs 4 curric
Plot: Env distribution of NSGA vs GA (vs random rh vs splcl)
(plot: promising experiments that were cut due to training time)

- env distributions anschuaen,
- env distribution normalisieren
- 2 Grafiken einbinden (objetive function smoothing Nr1, und vllt die data driven / model driven #2)
- Baseline trainieren ohne CL (random order der samples) --> Quasi 1 epoch mit 4 batches ( --> frag alex dazu)
stackedBarplot: heatmap: zeile curricula, spalte environments; Rot markeiren was oft ist und weiß was weniger




---------------------------
Low Prio
- (Multiobjective für NSGA machen)


Ideen
-------------------- FRAGEN ZUR MA -------------------
General Q:
- anderer termin ok
- etwas burnt out
- plots auf falscher seite (Tipps?)
- Benutzen von "we"?
- Wann erkläre ich denn das 1. mal unseren Ansatz? In den Basics bei RHEA? Weil in RW (Kapitel 3) möchte ich ja existierende sahen etwas mit unserem ansatz vergleiche
- SAC / ...  (wie am besten einbetten; erst mit minigrid gangbar machen -> dann ?)
- Was für "cherry on top gibt es denn noch"?
- [1][2], oder [1,2]
- Wie umgeht man dass der plot nicht im falschen kapitel landet ? (und auch balance zwischen Plotgröße und Lesbarkeit)


================

- Pool der available curricula verändern (schrieben aufgefallen)

-------------------- FRAGEN ZUR MA -------------------
Fragen zur MA
- Schreibstil, wie sehr den leser involvieren? "Now we are looking at ...", "As you can imagine ..."
- Wann erkläre ich denn das 1. mal unseren Ansatz? In den Basics bei RHEA? Weil in RW (Kapitel 3) möchte ich ja existierende sahen etwas mit unserem ansatz vergleiche
- Von welchem Wissensstand gehe ich für die Basics aus / was ist die Zielgruppe?
- Was für "cherry on top gibt es denn noch"?
- [1][2], oder [1,2]
- Std dev oder 95 CI ?
- appraoch vs algorithm
- Von welchem Wissensstand gehe ich für die Basics aus / was ist die Zielgruppe?




---------------------------------

Finde heraus wie weit alle experimente gekommen sind. --> Dann entscheide ggf mit 4kk

- automatische model-benennung statt model param
- alte modelnamen löschen (also die obvious debug waren bzw abgebrochen, damit ich merh üebrsicht im ls habe)




Random Notes / Ideas:
- optimize training times: early stopping / depending on threshold; or use a timelimit --> then combine w other methods (but probably bad since bad information to the EA)
- Ggf nicht immer 1. Schritt übernehmen des RHEA (ggf dynamisch machen), dynamische iterationLenghts1
- Ggf penalize, dass man immer gleiche envs nimmt ? Iwi encouragen dass er auch neue / sschwierige sachen ausprobiert (--> ggfh ängt das auch mit RH length zusammen)
- Ein automatischer Difficulty measurer wäre gut. Vllt kombinieren mit einem pre-trained model (dafür gabs iwo ein Paper)
- I could use difficult for the pool of available curricula as well (to better adjust to the models performacne); so it would have more to choose from, but then the evol optim would take a lot longer
- Überlegen wie man eine TSCL baseline machen könnte (bzw warum ich das nicht tue)


Irgendwann Recherche:
- Wo performt hard-to-easy besser als CL und warum? Was ist die Idee dahinter überhaupt?




- Ausprobieren mit 8 Envs oder so (zB mit den Empties)
- Ggf den Eval so umändern, dass man sich auf aktuellen Skill fokussiert (also zB nur 8x8 für alle "ähnlichen" vs immer alles durch; gerade bei > 4 envs wird es auch schwer.
    ; ggf auch iwi past in betracht ziehen
    Man könnte wahrscheinlich auch besser paralelisieren (wenn args.procs > args.episodes ist)




=============================================================

# TODO plot the snapshot vs curricReward problem ---> do some experiments. How does the curricLength influence results? How does gamma influence results?
Random Gedanken
- Das Unlearning Problem: wie genau funktionieren die updates überhaupt (2560 update schritte, oder 1x pro level)
- RH Probleme? Was wenn man zB erst 2 Mio mal 16x16 trainieren muss, bevor man Fortschritte sieht? Wenn 1 Horizon bei 500k ist & die Iterationen pro Env noch niedriger sind
- minimize ersetzen auf das .hasNext() und dann abbrechen bei konvergenz (falls man später viele Gens machen will) --> could save time with EA

===========================================================================================

Changelog / Erkenntnisse
- Versucht 8x8 zu selten,16x16 sowieso
- schlechte Rewardstruktur --> - anpassen, wenn gewisse performance erreicht wird (-> ermutigen von 16x16)
- diff1 & 2 haben kaum unterschiede auf laufzeit
- maxSteps beeifnlusst performance (ggf berücksichtigen? Difficulty = 2 sollte ja nicht die performance schmälern, nur weil es schwerer ist)
-> ggf 2* max_reward - actual_reward * difficulty
- das dauert alles sehr lange und ist dann irgendwie nicht aussagefähig. --> ggf lieber 2-3 experimente für 16h laufen lassen statt 6x8h



- 8x8, vor allem 16x16 wurde fast nie ausgewählt. Daher Reward anpassen, um ermutigen das zu tun
- Reward am ende zu viel gewichtung
- envDifficulty (aka maxSteps) lässt reward etwas verzerrt aussehen; daher multiplier
- Difficulty Cutoffs: .25 / .75



17.05 - 24.05:
5x5 viewsize, dafür kleinere Level 4 7 9 12 (bzw 6 8 10 12) --> schicht entfernt im netz
-- Fix mit dem Tensorboard Bug
- bisschen history aufgeschrieben was wann warum passiert ist
- rewards normalisieren (damit man nicht verzerrt wird, ob es 3 oder 4 envs sind)
- Cuda broken ??
- Experiment: 4 Para trainieren Baseline  ( --> Reward instant bei 32 / 35); training mit pur 16x16 scheitert immer noch, paar h laufen lassen
- RRH Experiment (wollte eig mit neuen Envs testen ...) ; sehr jumpy ( --> colab)


25.05 - 30.05
?


31.05 - 9.6
- Difficulty verursacht zu große Spikes
- Difficulty zeitbasiert machen
- Cluster angefangen bzw. etwas startprobleme
- viel an der Evaluate rumgebastelt (so dass man jetzt mehreere models vergleichen kann)
- viele Experimente laufen lassen
- Baseline mit logs gemacht

10.06 - 20.06
- eval auf Dataframe umstellen statt händisch
- Clusterexperimente anfangen
- letzten bugs fixen
- anfangen schreiben


21.06 - 28.06
exerimente laufen lassen
schreiben


-------------===============================
Meetingnotes:
einschärnkungen auch benenne ( alle kombinationen nicht möglich zu testen) -> es geht um Gefühl kriegen

-----------------------

ALTE NOTES
- ggf nur 1 leichte Env ist zu wenig
- 100k iterationen pro step zu wenig

=============---------------------------------------------------===
ZUR MA
60-80 Seiten
Pareto optimum (die linie für evol)
Sobel Sampling (funzt wahrsch nur für reel-wertige)
am ende ggf bayesian optimization ( zB 2 Params gleichzeitg variieren lasesn)





============================================================
SEEDLISTE
 1
 9152
 2330
 1214
 8515

 2529
 8258
 1517
  185
 3053

 9030
 4221
 2450
 7477
 1938
 1291
 8646
 1032
 6646
 1315
 6471
 3259
 9607